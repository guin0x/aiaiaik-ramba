{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install h5py\n",
    "# !pip install pandas matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install scipy\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "import copy\n",
    "import h5py\n",
    "import itertools\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from model.model_3D import *\n",
    "from model.train_eval import *\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from postprocessing.save_results import *\n",
    "from postprocessing.plot_results import *\n",
    "from postprocessing.metrics import single_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "### check if cuda is available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import NDVI data\n",
    "\n",
    "def load_with_hdf5(name):\n",
    "    \"\"\"\n",
    "    Load tensor data from HDF5 with gzip compression\n",
    "    \"\"\"\n",
    "    with h5py.File(f\"data/{name}.h5\", \"r\") as f:\n",
    "        loaded_features = torch.from_numpy(f[\"features\"][:])\n",
    "        loaded_labels = torch.from_numpy(f[\"labels\"][:])\n",
    "    return TensorDataset(loaded_features, loaded_labels)\n",
    "\n",
    "train_set = load_with_hdf5(\"train_set_ndvi_v7\")\n",
    "val_set = load_with_hdf5(\"val_set_ndvi_v7\")\n",
    "test_set = load_with_hdf5(\"test_set_ndvi_v7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 518 samples\n",
      "Validation set: 19 samples\n",
      "Test set: 19 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set: {len(train_set)} samples\")\n",
    "print(f\"Validation set: {len(val_set)} samples\")\n",
    "print(f\"Test set: {len(test_set)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([518, 2, 4, 1000, 500])\n",
      "torch.Size([518, 1000, 500])\n"
     ]
    }
   ],
   "source": [
    "print(train_set.tensors[0].shape)\n",
    "print(train_set.tensors[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_stats():\n",
    "    print((torch.cuda.memory_allocated()/1024**2), \"Memory allocated\")\n",
    "    print(torch.cuda.memory_cached()/1024**2, \"Memory cached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(batch_size, learning_rate, init_hid_dim, num_epochs=100, device='cuda'):\n",
    "    # Initialize model\n",
    "    model = UNet3D(\n",
    "        n_channels=train_set[0][0].shape[0],\n",
    "        n_classes=1,\n",
    "        init_hid_dim=init_hid_dim,\n",
    "        kernel_size=3,\n",
    "        pooling='max',\n",
    "        bilinear=False,\n",
    "        drop_channels=False\n",
    "    )\n",
    "\n",
    "    # Clear CUDA cache and run garbage collection before training loop\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    num_parameters = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Number of parameters: {num_parameters:.2e}.\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=15, gamma=0.75)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    csi_scores = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Training step\n",
    "        train_loss = training_unet(model, train_loader, optimizer, device=device, loss_f='BCE', water_threshold=0.5)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation step\n",
    "        with torch.no_grad():  # Prevent gradient computation in validation\n",
    "            val_loss, val_accuracy, val_precision, val_recall, val_f1_score, val_csi_score = validation_unet(\n",
    "                model, val_loader, device=device, loss_f='BCE', water_threshold=0.5\n",
    "            )\n",
    "\n",
    "        # Move metrics to CPU and append to lists\n",
    "        val_losses.append(val_loss)\n",
    "        accuracies.append(val_accuracy)\n",
    "        precisions.append(val_precision)\n",
    "        recalls.append(val_recall)\n",
    "        f1_scores.append(val_f1_score)\n",
    "        csi_scores.append(val_csi_score)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = copy.deepcopy(model).cpu()  # Move model to CPU for storage\n",
    "\n",
    "        # Print progress\n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"Epoch: {epoch} | Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, \"\n",
    "                  f\"Best Validation Loss: {best_loss:.4f}\")\n",
    "            print(f\"Metrics | Accuracy: {val_accuracy:.3f}, Precision: {val_precision:.3f}, Recall: {val_recall:.3f}, \"\n",
    "                  f\"F1-score: {val_f1_score:.3f}, CSI-score: {val_csi_score:.3f}\")\n",
    "            print(f\"Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    # Cleanup\n",
    "    del optimizer, val_loss, model, train_loader, train_loss\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return best_loss, best_model, train_losses, val_losses, accuracies, precisions, recalls, f1_scores, csi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for Batch Size=16, Learning Rate=0.05, Init Hid Dim=8\n",
      "Number of parameters: 4.87e+05.\n",
      "Epoch: 1 | Training Loss: 0.2446, Validation Loss: 0.2392, Best Validation Loss: 0.2392\n",
      "Metrics | Accuracy: 0.914, Precision: 0.565, Recall: 0.767, F1-score: 0.651, CSI-score: 0.483\n",
      "Learning Rate: 0.050000\n",
      "Epoch: 2 | Training Loss: 0.1781, Validation Loss: 0.1660, Best Validation Loss: 0.1660\n",
      "Metrics | Accuracy: 0.926, Precision: 0.633, Recall: 0.695, F1-score: 0.662, CSI-score: 0.496\n",
      "Learning Rate: 0.050000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs16_lr0.05_hid8_epoch2.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "BCE loss:          1.648e-01\n",
      "Accuracy:          0.928\n",
      "Precision:         0.669\n",
      "Recall:            0.738\n",
      "F1 score:          0.702\n",
      "CSI score:         0.541\n"
     ]
    }
   ],
   "source": [
    "# Test first with Antonio's Hyperparameters\n",
    "batch_size = 16\n",
    "learning_rate = 0.05\n",
    "init_hid_dim = 8\n",
    "num_epochs = 2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "loss_f = 'BCE'\n",
    "machine = 'machine_1'\n",
    "\n",
    "# Clear GPU memory before starting\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Train and validate\n",
    "print(f\"Running training for Batch Size={batch_size}, Learning Rate={learning_rate}, Init Hid Dim={init_hid_dim}\")\n",
    "\n",
    "val_loss, best_model, train_losses, val_losses, accuracies, precisions, recalls, f1_scores, csi_scores = train_and_validate(\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    init_hid_dim=init_hid_dim,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Clear GPU memory after training\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Save the best model\n",
    "save_model_path(\n",
    "    machine=machine,\n",
    "    model=best_model,  # No need to move to CPU if metrics are not tensors\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    init_hid_dim=init_hid_dim,\n",
    "    epochs=num_epochs,\n",
    "    dir_output=\"model/models_trained\"\n",
    ")\n",
    "\n",
    "# Save training and validation metrics\n",
    "save_losses_metrics(\n",
    "    machine=machine,\n",
    "    train_losses=train_losses,\n",
    "    val_losses=val_losses,\n",
    "    metrics=[accuracies, precisions, recalls, f1_scores, csi_scores],\n",
    "    batch_size=batch_size, \n",
    "    learning_rate=learning_rate, \n",
    "    init_hid_dim=init_hid_dim, \n",
    "    epochs=num_epochs,\n",
    "    dir_output=\"model/losses_metrics\" \n",
    ")\n",
    "\n",
    "# Define the test loader\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Test the best model\n",
    "with torch.no_grad():  # Disable gradient computation during testing\n",
    "    model_loss = copy.deepcopy(best_model)\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_csi_score = validation_unet(\n",
    "        model_loss, test_loader, device=device, loss_f=loss_f\n",
    "    )\n",
    "\n",
    "print(f'Average metrics for test dataset using model with best validation loss:\\n\\n\\\n",
    "BCE loss:          {test_loss:.3e}\\n\\\n",
    "Accuracy:          {test_accuracy:.3f}\\n\\\n",
    "Precision:         {test_precision:.3f}\\n\\\n",
    "Recall:            {test_recall:.3f}\\n\\\n",
    "F1 score:          {test_f1_score:.3f}\\n\\\n",
    "CSI score:         {test_csi_score:.3f}')\n",
    "\n",
    "# Cleanup to free memory\n",
    "del best_model, model_loss, test_loader\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Batch size=8, Learning rate=0.01, Init Hid Dim=8\n",
      "Number of parameters: 4.87e+05.\n",
      "Epoch: 1 | Training Loss: 0.3359, Validation Loss: 0.1782, Best Validation Loss: 0.1782\n",
      "Metrics | Accuracy: 0.925, Precision: 0.644, Recall: 0.662, F1-score: 0.653, CSI-score: 0.485\n",
      "Learning Rate: 0.010000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs8_lr0.01_hid8_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          1.742e-01\n",
      "            Accuracy:          0.928\n",
      "            Precision:         0.676\n",
      "            Recall:            0.710\n",
      "            F1 score:          0.692\n",
      "            CSI score:         0.530\n",
      "Testing: Batch size=8, Learning rate=0.01, Init Hid Dim=16\n",
      "Number of parameters: 1.95e+06.\n",
      "Epoch: 1 | Training Loss: 0.2299, Validation Loss: 0.1614, Best Validation Loss: 0.1614\n",
      "Metrics | Accuracy: 0.925, Precision: 0.650, Recall: 0.648, F1-score: 0.649, CSI-score: 0.481\n",
      "Learning Rate: 0.010000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs8_lr0.01_hid16_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          1.555e-01\n",
      "            Accuracy:          0.929\n",
      "            Precision:         0.687\n",
      "            Recall:            0.699\n",
      "            F1 score:          0.693\n",
      "            CSI score:         0.530\n",
      "Testing: Batch size=8, Learning rate=0.01, Init Hid Dim=32\n",
      "Number of parameters: 7.77e+06.\n",
      "Epoch: 1 | Training Loss: 0.2150, Validation Loss: 0.1610, Best Validation Loss: 0.1610\n",
      "Metrics | Accuracy: 0.925, Precision: 0.668, Recall: 0.602, F1-score: 0.633, CSI-score: 0.464\n",
      "Learning Rate: 0.010000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs8_lr0.01_hid32_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          1.547e-01\n",
      "            Accuracy:          0.929\n",
      "            Precision:         0.704\n",
      "            Recall:            0.659\n",
      "            F1 score:          0.681\n",
      "            CSI score:         0.516\n",
      "Testing: Batch size=8, Learning rate=0.05, Init Hid Dim=8\n",
      "Number of parameters: 4.87e+05.\n",
      "Epoch: 1 | Training Loss: 0.2120, Validation Loss: 0.1664, Best Validation Loss: 0.1664\n",
      "Metrics | Accuracy: 0.925, Precision: 0.668, Recall: 0.598, F1-score: 0.631, CSI-score: 0.461\n",
      "Learning Rate: 0.050000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs8_lr0.05_hid8_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          1.592e-01\n",
      "            Accuracy:          0.928\n",
      "            Precision:         0.697\n",
      "            Recall:            0.656\n",
      "            F1 score:          0.676\n",
      "            CSI score:         0.511\n",
      "Testing: Batch size=8, Learning rate=0.05, Init Hid Dim=16\n",
      "Number of parameters: 1.95e+06.\n",
      "Epoch: 1 | Training Loss: 0.2041, Validation Loss: 0.1646, Best Validation Loss: 0.1646\n",
      "Metrics | Accuracy: 0.925, Precision: 0.684, Recall: 0.550, F1-score: 0.610, CSI-score: 0.439\n",
      "Learning Rate: 0.050000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs8_lr0.05_hid16_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          1.605e-01\n",
      "            Accuracy:          0.926\n",
      "            Precision:         0.712\n",
      "            Recall:            0.601\n",
      "            F1 score:          0.652\n",
      "            CSI score:         0.484\n",
      "Testing: Batch size=8, Learning rate=0.05, Init Hid Dim=32\n",
      "Number of parameters: 7.77e+06.\n",
      "Epoch: 1 | Training Loss: 0.2057, Validation Loss: 0.1654, Best Validation Loss: 0.1654\n",
      "Metrics | Accuracy: 0.923, Precision: 0.637, Recall: 0.656, F1-score: 0.647, CSI-score: 0.478\n",
      "Learning Rate: 0.050000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs8_lr0.05_hid32_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          1.608e-01\n",
      "            Accuracy:          0.927\n",
      "            Precision:         0.675\n",
      "            Recall:            0.700\n",
      "            F1 score:          0.687\n",
      "            CSI score:         0.524\n",
      "Testing: Batch size=8, Learning rate=0.1, Init Hid Dim=8\n",
      "Number of parameters: 4.87e+05.\n",
      "Epoch: 1 | Training Loss: 0.2218, Validation Loss: 0.8796, Best Validation Loss: 0.8796\n",
      "Metrics | Accuracy: 0.912, Precision: 0.608, Recall: 0.475, F1-score: 0.534, CSI-score: 0.364\n",
      "Learning Rate: 0.100000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs8_lr0.1_hid8_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          5.564e-01\n",
      "            Accuracy:          0.915\n",
      "            Precision:         0.655\n",
      "            Recall:            0.552\n",
      "            F1 score:          0.599\n",
      "            CSI score:         0.427\n",
      "Testing: Batch size=8, Learning rate=0.1, Init Hid Dim=16\n",
      "Number of parameters: 1.95e+06.\n",
      "Epoch: 1 | Training Loss: 0.2207, Validation Loss: 0.4703, Best Validation Loss: 0.4703\n",
      "Metrics | Accuracy: 0.894, Precision: 0.648, Recall: 0.013, F1-score: 0.026, CSI-score: 0.013\n",
      "Learning Rate: 0.100000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs8_lr0.1_hid16_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          4.700e-01\n",
      "            Accuracy:          0.886\n",
      "            Precision:         0.730\n",
      "            Recall:            0.014\n",
      "            F1 score:          0.027\n",
      "            CSI score:         0.014\n",
      "Testing: Batch size=8, Learning rate=0.1, Init Hid Dim=32\n",
      "Number of parameters: 7.77e+06.\n",
      "Epoch: 1 | Training Loss: 0.1974, Validation Loss: 0.1630, Best Validation Loss: 0.1630\n",
      "Metrics | Accuracy: 0.923, Precision: 0.643, Recall: 0.636, F1-score: 0.640, CSI-score: 0.471\n",
      "Learning Rate: 0.100000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs8_lr0.1_hid32_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          1.566e-01\n",
      "            Accuracy:          0.928\n",
      "            Precision:         0.683\n",
      "            Recall:            0.687\n",
      "            F1 score:          0.685\n",
      "            CSI score:         0.521\n",
      "Testing: Batch size=16, Learning rate=0.01, Init Hid Dim=8\n",
      "Number of parameters: 4.87e+05.\n",
      "Epoch: 1 | Training Loss: 0.4727, Validation Loss: 0.4876, Best Validation Loss: 0.4876\n",
      "Metrics | Accuracy: 0.814, Precision: 0.353, Recall: 0.940, F1-score: 0.513, CSI-score: 0.345\n",
      "Learning Rate: 0.010000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs16_lr0.01_hid8_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          5.045e-01\n",
      "            Accuracy:          0.805\n",
      "            Precision:         0.366\n",
      "            Recall:            0.954\n",
      "            F1 score:          0.529\n",
      "            CSI score:         0.360\n",
      "Testing: Batch size=16, Learning rate=0.01, Init Hid Dim=16\n",
      "Number of parameters: 1.95e+06.\n",
      "Epoch: 1 | Training Loss: 0.3027, Validation Loss: 0.1763, Best Validation Loss: 0.1763\n",
      "Metrics | Accuracy: 0.916, Precision: 0.574, Recall: 0.765, F1-score: 0.656, CSI-score: 0.488\n",
      "Learning Rate: 0.010000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs16_lr0.01_hid16_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          1.703e-01\n",
      "            Accuracy:          0.921\n",
      "            Precision:         0.618\n",
      "            Recall:            0.807\n",
      "            F1 score:          0.700\n",
      "            CSI score:         0.538\n",
      "Testing: Batch size=16, Learning rate=0.01, Init Hid Dim=32\n",
      "Number of parameters: 7.77e+06.\n",
      "Epoch: 1 | Training Loss: 0.2383, Validation Loss: 0.4846, Best Validation Loss: 0.4846\n",
      "Metrics | Accuracy: 0.813, Precision: 0.355, Recall: 0.959, F1-score: 0.518, CSI-score: 0.350\n",
      "Learning Rate: 0.010000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs16_lr0.01_hid32_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          4.774e-01\n",
      "            Accuracy:          0.822\n",
      "            Precision:         0.388\n",
      "            Recall:            0.963\n",
      "            F1 score:          0.553\n",
      "            CSI score:         0.383\n",
      "Testing: Batch size=16, Learning rate=0.05, Init Hid Dim=8\n",
      "Number of parameters: 4.87e+05.\n",
      "Epoch: 1 | Training Loss: 0.2715, Validation Loss: 0.3481, Best Validation Loss: 0.3481\n",
      "Metrics | Accuracy: 0.872, Precision: 0.447, Recall: 0.911, F1-score: 0.600, CSI-score: 0.428\n",
      "Learning Rate: 0.050000\n",
      "Metrics saved at: model/losses_metrics/machine_1_losses_metrics_NDVI_bs16_lr0.05_hid8_epoch1.csv\n",
      "Average metrics for test dataset using model with best validation loss:\n",
      "\n",
      "            BCE loss:          3.294e-01\n",
      "            Accuracy:          0.882\n",
      "            Precision:         0.492\n",
      "            Recall:            0.925\n",
      "            F1 score:          0.642\n",
      "            CSI score:         0.473\n",
      "Results saved.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Optimization\n",
    "batch_sizes = [8, 16, 32]\n",
    "learning_rates = [0.01, 0.05, 0.1]\n",
    "init_hid_dims = [8, 16, 32]\n",
    "num_epochs = 1\n",
    "loss_f = 'BCE'  # Define loss function for training and testing\n",
    "machine = 'machine_1'  # Dynamically determine machine (e.g., passed as an argument or environment variable)\n",
    "\n",
    "# Split combinations across machines\n",
    "all_combinations = list(itertools.product(batch_sizes, learning_rates, init_hid_dims))\n",
    "split_index = len(all_combinations) // 2\n",
    "combinations_split = {\n",
    "    \"machine_1\": all_combinations[:split_index],\n",
    "    \"machine_2\": all_combinations[split_index:]\n",
    "}\n",
    "\n",
    "# Dynamically assign combinations based on the `machine` variable\n",
    "combinations = combinations_split.get(machine, [])\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "# Run grid search\n",
    "for batch_size, learning_rate, init_hid_dim in combinations:\n",
    "    print(f\"Testing: Batch size={batch_size}, Learning rate={learning_rate}, Init Hid Dim={init_hid_dim}\")\n",
    "\n",
    "    # Clear CUDA memory and garbage collect\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # Train and validate\n",
    "    val_loss, best_model, train_losses, val_losses, accuracies, precisions, recalls, f1_scores, csi_scores = train_and_validate(\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        init_hid_dim=init_hid_dim,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Save the best model\n",
    "    save_model_path(machine=machine,\n",
    "        model=best_model,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        init_hid_dim=init_hid_dim,\n",
    "        epochs=num_epochs,\n",
    "        dir_output=\"model/models_trained\"\n",
    "    )\n",
    "\n",
    "    # Save training and validation metrics\n",
    "    save_losses_metrics(machine=machine,\n",
    "        train_losses=train_losses,\n",
    "        val_losses=val_losses,\n",
    "        metrics=[accuracies, precisions, recalls, f1_scores, csi_scores],\n",
    "        batch_size=batch_size, \n",
    "        learning_rate=learning_rate, \n",
    "        init_hid_dim=init_hid_dim, \n",
    "        epochs=num_epochs,\n",
    "        dir_output=\"model/losses_metrics\" \n",
    "    )\n",
    "\n",
    "    # Define the test loader\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Test the best model on the test dataset\n",
    "    with torch.no_grad():\n",
    "        test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_csi_score = validation_unet(\n",
    "            best_model, test_loader, device=device, loss_f=loss_f\n",
    "        )\n",
    "\n",
    "    print(f'Average metrics for test dataset using model with best validation loss:\\n\\n\\\n",
    "            {loss_f} loss:          {test_loss:.3e}\\n\\\n",
    "            Accuracy:          {test_accuracy:.3f}\\n\\\n",
    "            Precision:         {test_precision:.3f}\\n\\\n",
    "            Recall:            {test_recall:.3f}\\n\\\n",
    "            F1 score:          {test_f1_score:.3f}\\n\\\n",
    "            CSI score:         {test_csi_score:.3f}')\n",
    "\n",
    "    # Append results\n",
    "    results.append((\n",
    "        batch_size, learning_rate, init_hid_dim, \n",
    "        float(val_loss), float(test_loss), \n",
    "        float(test_accuracy), float(test_precision), float(test_recall), \n",
    "        float(test_f1_score), float(test_csi_score)\n",
    "    ))\n",
    "\n",
    "    # Cleanup\n",
    "    del best_model, test_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Save results to a CSV file\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    'Batch Size', 'Learning Rate', 'Init Hid Dim', \n",
    "    'Validation Loss', 'Test Loss', 'Test Accuracy', \n",
    "    'Test Precision', 'Test Recall', 'Test F1 Score', 'Test CSI Score'\n",
    "])\n",
    "df_results.to_csv(f\"results_{machine}_{num_epochs}.csv\", index=False)\n",
    "print(\"Results saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
