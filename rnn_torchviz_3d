digraph {
	graph [size="62.25,62.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	136604671957712 [label="
 (16, 1, 1000, 500)" fillcolor=darkolivegreen1]
	136604671969360 [label=SigmoidBackward0]
	136604671969024 -> 136604671969360
	136604671969024 [label=ConvolutionBackward0]
	136604671969600 -> 136604671969024
	136604671969600 [label=ReluBackward0]
	136604671968880 -> 136604671969600
	136604671968880 [label=NativeBatchNormBackward0]
	136604671968640 -> 136604671968880
	136604671968640 [label=ConvolutionBackward0]
	136604671968448 -> 136604671968640
	136604671968448 [label=ReluBackward0]
	136604671968304 -> 136604671968448
	136604671968304 [label=NativeBatchNormBackward0]
	136604671968112 -> 136604671968304
	136604671968112 [label=ConvolutionBackward0]
	136604671967872 -> 136604671968112
	136604671967872 [label=CatBackward0]
	136604671969792 -> 136604671967872
	136604671969792 [label=ReluBackward0]
	136604671969936 -> 136604671969792
	136604671969936 [label=NativeBatchNormBackward0]
	136604671970032 -> 136604671969936
	136604671970032 [label=ConvolutionBackward0]
	136604671970224 -> 136604671970032
	136604671970224 [label=ReluBackward0]
	136604671970368 -> 136604671970224
	136604671970368 [label=NativeBatchNormBackward0]
	136604671970464 -> 136604671970368
	136604671970464 [label=ConvolutionBackward0]
	136604671970656 -> 136604671970464
	136604671970656 [label=SqueezeBackward1]
	136604671970800 -> 136604671970656
	136604671970800 [label=ReluBackward0]
	136604671970896 -> 136604671970800
	136604671970896 [label=ConvolutionBackward0]
	136604671970992 -> 136604671970896
	136604707998512 [label="temporal_conv.conv3d.weight
 (8, 1, 4, 3, 3)" fillcolor=lightblue]
	136604707998512 -> 136604671970992
	136604671970992 [label=AccumulateGrad]
	136604671970608 -> 136604671970464
	136613649290064 [label="inc.double_conv.0.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	136613649290064 -> 136604671970608
	136604671970608 [label=AccumulateGrad]
	136604671970416 -> 136604671970368
	136604707904368 [label="inc.double_conv.1.weight
 (8)" fillcolor=lightblue]
	136604707904368 -> 136604671970416
	136604671970416 [label=AccumulateGrad]
	136604671970272 -> 136604671970368
	136604707902528 [label="inc.double_conv.1.bias
 (8)" fillcolor=lightblue]
	136604707902528 -> 136604671970272
	136604671970272 [label=AccumulateGrad]
	136604671970176 -> 136604671970032
	136604707998832 [label="inc.double_conv.3.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	136604707998832 -> 136604671970176
	136604671970176 [label=AccumulateGrad]
	136604671969984 -> 136604671969936
	136604707998912 [label="inc.double_conv.4.weight
 (8)" fillcolor=lightblue]
	136604707998912 -> 136604671969984
	136604671969984 [label=AccumulateGrad]
	136604671969840 -> 136604671969936
	136604707998992 [label="inc.double_conv.4.bias
 (8)" fillcolor=lightblue]
	136604707998992 -> 136604671969840
	136604671969840 [label=AccumulateGrad]
	136604671967728 -> 136604671967872
	136604671967728 [label=ConstantPadNdBackward0]
	136604671970128 -> 136604671967728
	136604671970128 [label=ConvolutionBackward0]
	136604671970512 -> 136604671970128
	136604671970512 [label=ReluBackward0]
	136604671970752 -> 136604671970512
	136604671970752 [label=NativeBatchNormBackward0]
	136604671971040 -> 136604671970752
	136604671971040 [label=ConvolutionBackward0]
	136604671971232 -> 136604671971040
	136604671971232 [label=ReluBackward0]
	136604671971376 -> 136604671971232
	136604671971376 [label=NativeBatchNormBackward0]
	136604671971472 -> 136604671971376
	136604671971472 [label=ConvolutionBackward0]
	136604671971664 -> 136604671971472
	136604671971664 [label=CatBackward0]
	136604671971808 -> 136604671971664
	136604671971808 [label=ReluBackward0]
	136604671971952 -> 136604671971808
	136604671971952 [label=NativeBatchNormBackward0]
	136604671972048 -> 136604671971952
	136604671972048 [label=ConvolutionBackward0]
	136604671972240 -> 136604671972048
	136604671972240 [label=ReluBackward0]
	136604671972384 -> 136604671972240
	136604671972384 [label=NativeBatchNormBackward0]
	136604671972480 -> 136604671972384
	136604671972480 [label=ConvolutionBackward0]
	136604671972672 -> 136604671972480
	136604671972672 [label=MaxPool2DWithIndicesBackward0]
	136604671969792 -> 136604671972672
	136604671972624 -> 136604671972480
	136604707999392 [label="down1.pool_conv.1.double_conv.0.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	136604707999392 -> 136604671972624
	136604671972624 [label=AccumulateGrad]
	136604671972432 -> 136604671972384
	136604707999472 [label="down1.pool_conv.1.double_conv.1.weight
 (16)" fillcolor=lightblue]
	136604707999472 -> 136604671972432
	136604671972432 [label=AccumulateGrad]
	136604671972288 -> 136604671972384
	136604707999552 [label="down1.pool_conv.1.double_conv.1.bias
 (16)" fillcolor=lightblue]
	136604707999552 -> 136604671972288
	136604671972288 [label=AccumulateGrad]
	136604671972192 -> 136604671972048
	136604708000032 [label="down1.pool_conv.1.double_conv.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	136604708000032 -> 136604671972192
	136604671972192 [label=AccumulateGrad]
	136604671972000 -> 136604671971952
	136604708000112 [label="down1.pool_conv.1.double_conv.4.weight
 (16)" fillcolor=lightblue]
	136604708000112 -> 136604671972000
	136604671972000 [label=AccumulateGrad]
	136604671971856 -> 136604671971952
	136604708000192 [label="down1.pool_conv.1.double_conv.4.bias
 (16)" fillcolor=lightblue]
	136604708000192 -> 136604671971856
	136604671971856 [label=AccumulateGrad]
	136604671971760 -> 136604671971664
	136604671971760 [label=ConstantPadNdBackward0]
	136604671972144 -> 136604671971760
	136604671972144 [label=ConvolutionBackward0]
	136604671972528 -> 136604671972144
	136604671972528 [label=ReluBackward0]
	136604671972816 -> 136604671972528
	136604671972816 [label=NativeBatchNormBackward0]
	136604671972912 -> 136604671972816
	136604671972912 [label=ConvolutionBackward0]
	136604671973104 -> 136604671972912
	136604671973104 [label=ReluBackward0]
	136604671973248 -> 136604671973104
	136604671973248 [label=NativeBatchNormBackward0]
	136604671973344 -> 136604671973248
	136604671973344 [label=ConvolutionBackward0]
	136604671973536 -> 136604671973344
	136604671973536 [label=CatBackward0]
	136604671973680 -> 136604671973536
	136604671973680 [label=ReluBackward0]
	136604671973824 -> 136604671973680
	136604671973824 [label=NativeBatchNormBackward0]
	136604671973920 -> 136604671973824
	136604671973920 [label=ConvolutionBackward0]
	136604671974112 -> 136604671973920
	136604671974112 [label=ReluBackward0]
	136604671974256 -> 136604671974112
	136604671974256 [label=NativeBatchNormBackward0]
	136604671974352 -> 136604671974256
	136604671974352 [label=ConvolutionBackward0]
	136604671974544 -> 136604671974352
	136604671974544 [label=MaxPool2DWithIndicesBackward0]
	136604671971808 -> 136604671974544
	136604671974496 -> 136604671974352
	136604708000672 [label="down2.pool_conv.1.double_conv.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	136604708000672 -> 136604671974496
	136604671974496 [label=AccumulateGrad]
	136604671974304 -> 136604671974256
	136604708000752 [label="down2.pool_conv.1.double_conv.1.weight
 (32)" fillcolor=lightblue]
	136604708000752 -> 136604671974304
	136604671974304 [label=AccumulateGrad]
	136604671974160 -> 136604671974256
	136604708000832 [label="down2.pool_conv.1.double_conv.1.bias
 (32)" fillcolor=lightblue]
	136604708000832 -> 136604671974160
	136604671974160 [label=AccumulateGrad]
	136604671974064 -> 136604671973920
	136604708001312 [label="down2.pool_conv.1.double_conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	136604708001312 -> 136604671974064
	136604671974064 [label=AccumulateGrad]
	136604671973872 -> 136604671973824
	136604708001392 [label="down2.pool_conv.1.double_conv.4.weight
 (32)" fillcolor=lightblue]
	136604708001392 -> 136604671973872
	136604671973872 [label=AccumulateGrad]
	136604671973728 -> 136604671973824
	136604708001472 [label="down2.pool_conv.1.double_conv.4.bias
 (32)" fillcolor=lightblue]
	136604708001472 -> 136604671973728
	136604671973728 [label=AccumulateGrad]
	136604671973632 -> 136604671973536
	136604671973632 [label=ConstantPadNdBackward0]
	136604671974016 -> 136604671973632
	136604671974016 [label=ConvolutionBackward0]
	136604671974400 -> 136604671974016
	136604671974400 [label=ReluBackward0]
	136604671974688 -> 136604671974400
	136604671974688 [label=NativeBatchNormBackward0]
	136604671974784 -> 136604671974688
	136604671974784 [label=ConvolutionBackward0]
	136604671974976 -> 136604671974784
	136604671974976 [label=ReluBackward0]
	136604671975120 -> 136604671974976
	136604671975120 [label=NativeBatchNormBackward0]
	136604671975216 -> 136604671975120
	136604671975216 [label=ConvolutionBackward0]
	136604671975408 -> 136604671975216
	136604671975408 [label=CatBackward0]
	136604671975552 -> 136604671975408
	136604671975552 [label=ReluBackward0]
	136604671975696 -> 136604671975552
	136604671975696 [label=NativeBatchNormBackward0]
	136604671975792 -> 136604671975696
	136604671975792 [label=ConvolutionBackward0]
	136604671975984 -> 136604671975792
	136604671975984 [label=ReluBackward0]
	136604671976128 -> 136604671975984
	136604671976128 [label=NativeBatchNormBackward0]
	136604671976224 -> 136604671976128
	136604671976224 [label=ConvolutionBackward0]
	136604671976416 -> 136604671976224
	136604671976416 [label=MaxPool2DWithIndicesBackward0]
	136604671973680 -> 136604671976416
	136604671976368 -> 136604671976224
	136604708001952 [label="down3.pool_conv.1.double_conv.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	136604708001952 -> 136604671976368
	136604671976368 [label=AccumulateGrad]
	136604671976176 -> 136604671976128
	136604708002032 [label="down3.pool_conv.1.double_conv.1.weight
 (64)" fillcolor=lightblue]
	136604708002032 -> 136604671976176
	136604671976176 [label=AccumulateGrad]
	136604671976032 -> 136604671976128
	136604708002112 [label="down3.pool_conv.1.double_conv.1.bias
 (64)" fillcolor=lightblue]
	136604708002112 -> 136604671976032
	136604671976032 [label=AccumulateGrad]
	136604671975936 -> 136604671975792
	136604708002592 [label="down3.pool_conv.1.double_conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	136604708002592 -> 136604671975936
	136604671975936 [label=AccumulateGrad]
	136604671975744 -> 136604671975696
	136604708002672 [label="down3.pool_conv.1.double_conv.4.weight
 (64)" fillcolor=lightblue]
	136604708002672 -> 136604671975744
	136604671975744 [label=AccumulateGrad]
	136604671975600 -> 136604671975696
	136604708002752 [label="down3.pool_conv.1.double_conv.4.bias
 (64)" fillcolor=lightblue]
	136604708002752 -> 136604671975600
	136604671975600 [label=AccumulateGrad]
	136604671975504 -> 136604671975408
	136604671975504 [label=ConstantPadNdBackward0]
	136604671975888 -> 136604671975504
	136604671975888 [label=ConvolutionBackward0]
	136604671976272 -> 136604671975888
	136604671976272 [label=ReluBackward0]
	136604671976560 -> 136604671976272
	136604671976560 [label=NativeBatchNormBackward0]
	136604671976656 -> 136604671976560
	136604671976656 [label=ConvolutionBackward0]
	136604671976848 -> 136604671976656
	136604671976848 [label=ReluBackward0]
	136604671976992 -> 136604671976848
	136604671976992 [label=NativeBatchNormBackward0]
	136604671977088 -> 136604671976992
	136604671977088 [label=ConvolutionBackward0]
	136604671977280 -> 136604671977088
	136604671977280 [label=MaxPool2DWithIndicesBackward0]
	136604671975552 -> 136604671977280
	136604671977232 -> 136604671977088
	136604708003232 [label="down4.pool_conv.1.double_conv.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	136604708003232 -> 136604671977232
	136604671977232 [label=AccumulateGrad]
	136604671977040 -> 136604671976992
	136604708003312 [label="down4.pool_conv.1.double_conv.1.weight
 (128)" fillcolor=lightblue]
	136604708003312 -> 136604671977040
	136604671977040 [label=AccumulateGrad]
	136604671976896 -> 136604671976992
	136604708003392 [label="down4.pool_conv.1.double_conv.1.bias
 (128)" fillcolor=lightblue]
	136604708003392 -> 136604671976896
	136604671976896 [label=AccumulateGrad]
	136604671976800 -> 136604671976656
	136604708003872 [label="down4.pool_conv.1.double_conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	136604708003872 -> 136604671976800
	136604671976800 [label=AccumulateGrad]
	136604671976608 -> 136604671976560
	136604708003952 [label="down4.pool_conv.1.double_conv.4.weight
 (128)" fillcolor=lightblue]
	136604708003952 -> 136604671976608
	136604671976608 [label=AccumulateGrad]
	136604671976464 -> 136604671976560
	136604708004032 [label="down4.pool_conv.1.double_conv.4.bias
 (128)" fillcolor=lightblue]
	136604708004032 -> 136604671976464
	136604671976464 [label=AccumulateGrad]
	136604671976320 -> 136604671975888
	136604708004512 [label="up1.up.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	136604708004512 -> 136604671976320
	136604671976320 [label=AccumulateGrad]
	136604671975648 -> 136604671975888
	136604708004592 [label="up1.up.bias
 (64)" fillcolor=lightblue]
	136604708004592 -> 136604671975648
	136604671975648 [label=AccumulateGrad]
	136604671975360 -> 136604671975216
	136604708004752 [label="up1.conv.double_conv.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	136604708004752 -> 136604671975360
	136604671975360 [label=AccumulateGrad]
	136604671975168 -> 136604671975120
	136604708004832 [label="up1.conv.double_conv.1.weight
 (64)" fillcolor=lightblue]
	136604708004832 -> 136604671975168
	136604671975168 [label=AccumulateGrad]
	136604671975024 -> 136604671975120
	136604708004912 [label="up1.conv.double_conv.1.bias
 (64)" fillcolor=lightblue]
	136604708004912 -> 136604671975024
	136604671975024 [label=AccumulateGrad]
	136604671974928 -> 136604671974784
	136604708005392 [label="up1.conv.double_conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	136604708005392 -> 136604671974928
	136604671974928 [label=AccumulateGrad]
	136604671974736 -> 136604671974688
	136604708005472 [label="up1.conv.double_conv.4.weight
 (64)" fillcolor=lightblue]
	136604708005472 -> 136604671974736
	136604671974736 [label=AccumulateGrad]
	136604671974592 -> 136604671974688
	136604708005552 [label="up1.conv.double_conv.4.bias
 (64)" fillcolor=lightblue]
	136604708005552 -> 136604671974592
	136604671974592 [label=AccumulateGrad]
	136604671974448 -> 136604671974016
	136604708006032 [label="up2.up.weight
 (64, 32, 2, 2)" fillcolor=lightblue]
	136604708006032 -> 136604671974448
	136604671974448 [label=AccumulateGrad]
	136604671973776 -> 136604671974016
	136604708006112 [label="up2.up.bias
 (32)" fillcolor=lightblue]
	136604708006112 -> 136604671973776
	136604671973776 [label=AccumulateGrad]
	136604671973488 -> 136604671973344
	136604708006272 [label="up2.conv.double_conv.0.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	136604708006272 -> 136604671973488
	136604671973488 [label=AccumulateGrad]
	136604671973296 -> 136604671973248
	136604708006352 [label="up2.conv.double_conv.1.weight
 (32)" fillcolor=lightblue]
	136604708006352 -> 136604671973296
	136604671973296 [label=AccumulateGrad]
	136604671973152 -> 136604671973248
	136604708006432 [label="up2.conv.double_conv.1.bias
 (32)" fillcolor=lightblue]
	136604708006432 -> 136604671973152
	136604671973152 [label=AccumulateGrad]
	136604671973056 -> 136604671972912
	136604708006912 [label="up2.conv.double_conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	136604708006912 -> 136604671973056
	136604671973056 [label=AccumulateGrad]
	136604671972864 -> 136604671972816
	136604708006992 [label="up2.conv.double_conv.4.weight
 (32)" fillcolor=lightblue]
	136604708006992 -> 136604671972864
	136604671972864 [label=AccumulateGrad]
	136604671972720 -> 136604671972816
	136604708007072 [label="up2.conv.double_conv.4.bias
 (32)" fillcolor=lightblue]
	136604708007072 -> 136604671972720
	136604671972720 [label=AccumulateGrad]
	136604671972576 -> 136604671972144
	136604708007552 [label="up3.up.weight
 (32, 16, 2, 2)" fillcolor=lightblue]
	136604708007552 -> 136604671972576
	136604671972576 [label=AccumulateGrad]
	136604671971904 -> 136604671972144
	136604708007632 [label="up3.up.bias
 (16)" fillcolor=lightblue]
	136604708007632 -> 136604671971904
	136604671971904 [label=AccumulateGrad]
	136604671971616 -> 136604671971472
	136604708007792 [label="up3.conv.double_conv.0.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	136604708007792 -> 136604671971616
	136604671971616 [label=AccumulateGrad]
	136604671971424 -> 136604671971376
	136604708007872 [label="up3.conv.double_conv.1.weight
 (16)" fillcolor=lightblue]
	136604708007872 -> 136604671971424
	136604671971424 [label=AccumulateGrad]
	136604671971280 -> 136604671971376
	136604708007952 [label="up3.conv.double_conv.1.bias
 (16)" fillcolor=lightblue]
	136604708007952 -> 136604671971280
	136604671971280 [label=AccumulateGrad]
	136604671971184 -> 136604671971040
	136604708008432 [label="up3.conv.double_conv.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	136604708008432 -> 136604671971184
	136604671971184 [label=AccumulateGrad]
	136604671971088 -> 136604671970752
	136604708008512 [label="up3.conv.double_conv.4.weight
 (16)" fillcolor=lightblue]
	136604708008512 -> 136604671971088
	136604671971088 [label=AccumulateGrad]
	136604671970944 -> 136604671970752
	136604708008592 [label="up3.conv.double_conv.4.bias
 (16)" fillcolor=lightblue]
	136604708008592 -> 136604671970944
	136604671970944 [label=AccumulateGrad]
	136604671970560 -> 136604671970128
	136604708009072 [label="up4.up.weight
 (16, 8, 2, 2)" fillcolor=lightblue]
	136604708009072 -> 136604671970560
	136604671970560 [label=AccumulateGrad]
	136604671969888 -> 136604671970128
	136604708009152 [label="up4.up.bias
 (8)" fillcolor=lightblue]
	136604708009152 -> 136604671969888
	136604671969888 [label=AccumulateGrad]
	136604671967920 -> 136604671968112
	136604708009312 [label="up4.conv.double_conv.0.weight
 (8, 16, 3, 3)" fillcolor=lightblue]
	136604708009312 -> 136604671967920
	136604671967920 [label=AccumulateGrad]
	136604671968160 -> 136604671968304
	136604708009392 [label="up4.conv.double_conv.1.weight
 (8)" fillcolor=lightblue]
	136604708009392 -> 136604671968160
	136604671968160 [label=AccumulateGrad]
	136604671968400 -> 136604671968304
	136604708009472 [label="up4.conv.double_conv.1.bias
 (8)" fillcolor=lightblue]
	136604708009472 -> 136604671968400
	136604671968400 [label=AccumulateGrad]
	136604671968496 -> 136604671968640
	136604708009952 [label="up4.conv.double_conv.3.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	136604708009952 -> 136604671968496
	136604671968496 [label=AccumulateGrad]
	136604671968832 -> 136604671968880
	136604708010032 [label="up4.conv.double_conv.4.weight
 (8)" fillcolor=lightblue]
	136604708010032 -> 136604671968832
	136604671968832 [label=AccumulateGrad]
	136604671969696 -> 136604671968880
	136604708010112 [label="up4.conv.double_conv.4.bias
 (8)" fillcolor=lightblue]
	136604708010112 -> 136604671969696
	136604671969696 [label=AccumulateGrad]
	136604671968976 -> 136604671969024
	136604708010592 [label="outc.conv.weight
 (1, 8, 1, 1)" fillcolor=lightblue]
	136604708010592 -> 136604671968976
	136604671968976 [label=AccumulateGrad]
	136604671969072 -> 136604671969024
	136604708010672 [label="outc.conv.bias
 (1)" fillcolor=lightblue]
	136604708010672 -> 136604671969072
	136604671969072 [label=AccumulateGrad]
	136604671969360 -> 136604671957712
}
